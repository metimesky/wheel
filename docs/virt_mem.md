# 虚拟内存管理

Wheel 的内存管理分为两层，底层是屋里内层管理，单位是页。上层是虚拟内层管理，提供任意大小的 object 的分配。需要注意的是，通常 OS 中用户层和内核层使用两种不同的虚拟内存管理器，本文只关心内核中的虚拟内存管理。

形象地说，虚拟内存管理就是提供 malloc 和 free 这样的功能。Wheel 的内核虚拟内存管理主要参照 SLUB 的设计。每一次 malloc 和 free 的对象叫做一个对象，对象有不同的类型，在 Wheel 中只根据不同的大小区分对象类型。每一种对象类型都有一串 slab，用单链表组织起来。每个 slab 都是若干连续的页（有多少个连续的页是固定的，虽然不同类型对象的 slab 可能不同），每个 slab 中都包含若干连续分布的对象，因此对象的地址是按照对象大小对齐的。在 slab 的尾部，可能存在一些对齐的字节，Wheel 使用 slab 最后的几个字节存储 slab 链表中下一个元素的位置、当前 slab 可用对象数量。由于页的大小是 4K 对齐的，因此下一个 slab 的地址的最后 12 位是零。每个 slab 最多有 512 个元素（最小分配单元为 8 字节），因此可以将这两个信息放在同一个 uint64_t 字段之中。

### 为什么不用 SLAB

Linux 内核里，SLUB 替换了 SLAB，因为 SLAB 有很多不好的地方——过于浪费内存、碎片化严重等。主要原因在于用位图表示每个对象是否分配，并且位图也在 slab 里面。

### binlist

我们将同类对象的 slab 组成的链表称作 bin，每个大小的对象都有一个 bin，因此将这些 bin 组织成 binlist 数组。

我们不想限制 malloc 分配大小的限制，用户可以使用 malloc 申请任意大小的内存。而对于大小超过 4KB 的对象，Wheel 会直接分配物理页，只有大小不足 4KB 的对象，才会使用 SLUB 技术。对于每一种类型的 bin 都需要规定 slab 大小，而这种规定是凭经验定的：

| object size (bytes) | slab size (pages) | num of objects |
|:-------------------:|:-----------------:|:--------------:|
|         16          |         1         |      255       |
|         24          |         1         |      170       |
|         32          |         1         |      127       |
|         40          |         1         |      102       |
|         48          |         1         |       85       |
|         56          |         1         |       73       |
|         64          |         1         |       63       |
|         72          |         1         |                |

bin 的结构：

``` c
struct bin {
    uint64_t first_slab_addr;
    uint64_t first_free_object;
} __attribute__((packed));
typedef struct bin bin_t;
```

可能某些大小的对象根本不存在，因此创建这些大小的 slab 纯属浪费。因此在初始化阶段，并不真正建立 slab，等到代码调用 malloc 进行内存分配时再创建。

### Meta-data as objects?

对于每个 slab，都要记录链表的下一个元素，和该 slab 中剩余未分配对象数目，和第一个未分配对象。这些信息如果放在 slab 里面，可能浪费内存空间。

在 Linux 内核里，这些 slab 元信息放在 struct page 结构体中，这个结构体每个物理页帧都有一个，而且是静态分配的，因此能够保证。

设想，既然 slab 的元数据可以表示为一个对象，为何这个对象不能用内存管理器管理。假设 slab 元数据是一个结构体，大小 16 字节，某类型对象的 slab 已满，需要创建新的 slab，这时首先使用 malloc 分配一个 16 字节的 slab 元数据对象，然后申请新的物理页，插入新的单链表元素，然后 malloc 返回。

这样做的话，malloc 执行过程中可能调用自身。最不幸的情况是，调用 `malloc(16)` 的时候遇到 slab 已满，必须再次调用自己。

原本的 SLUB 实现中，不同对象类型是有名称的，这里相当于名称就是 `generic16`、`generic32` 等。可以为 slab 元数据专门创建一种类型，该数据的分配和释放使用单独的 bin。但是单独的 bin 同样有这个问题，如果这个单独的 bin 中某个 slab 的对象即将用完，它同样面临着自己调用两次的问题。

因此，看来比较合理的方式，要么将元数据放在 slab 里面，要么每个 bin 在还剩两个元素的时候就应该分配新的 slab。保证不可能出现前面说的那种情况。

- - -

但是这种做法还是太复杂。由于 Wheel 的物理内存管理并没有给每个物理页创建结构体，所以只能把信息保存在 slab 里。如果对象是 512 字节大小，或其他 4K 整数幂部分。

* * *

# 2015-12-2 新想法

上面讨论的核心问题在于，如果要实现SLUB，每个slab都要放在链表之中，而如果在slab中加入元数据，就会丧失SLUB的优势，变回SLAB。Linux因为每个物理页都有一个struct page，因此可以解决这个问题，但Wheel为了省内存没有这么做。

因此我想到，不妨为内核堆的这些slab留出存放元数据的空间，也就是Linux中struct page的空间，不过这些空间不是启动时就分配的，而是随着系统的使用，创建新的slab的时候才去创建。

内核虚拟地址空间：

+------+--------+-----------+----------------+--
| BASE | KERNEL | KHeapMeta | Kernel Heap -> |
+------+--------+-----------+----------------+--

BASE是1M以下的内存，Wheel不去使用，KERNEL是内核代码、数据，包括管理物理内存用的buddy，都属于这一块。Kernel Heap是最后一部分，在内核堆与内核之间，是一段内核堆的元数据区。内核堆创建有多个slab，每个slab都是页对齐的，因此根据slab的地址，就能算出这个slab的下标，根据这个下标就能对应到KHeapMeta中。KHeapMeta是一个大数组，每个元素都是struct slab类型的，就像在Linux的struct page一样，只不过这里只存和slab相关的信息。

内核初始化的时候，会根据系统最大可用内存计算内核堆的上限，也就能算出最多需要多少slab，也就能够算出KHeapMeta的数组长度的上限，于是就能算出内核堆的起始地址。运行过程中，内核还要记录内核堆的最后一个虚拟页的虚拟地址，因为这也是KHeapMeta中最后一个元素的位置，标记着KHeapMeta的已使用范围。对于已使用的KHeapMeta，内核需要为其分配物理页，当创建新的slab导致内核堆扩张，KHeapMeta数组已用部分增长，内核就（可能）要给KHeapMeta分配新的物理页，而内核堆使用量还比较小的时候，虽然KHeapMeta占用的空间固定，但是并不需要为其分配真正地物理页，同样能够起到节省内存的作用。



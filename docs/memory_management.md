## 分页

内存管理的硬件支持是分页机制。在 64 位模式下，分页是强制的，而且是 PAE 分页，PAE 分页意味着支持 2MB 大小的页。

在操作系统启动过程中，切换 64 位模式是最先执行的动作。因此在内存管理模块未启动的时候就需要建立分页。

## 初始分页

初始分页就是在切换64位模式的时候制定的分页映射。虽然当内存管理模块初始化之后可以改变页表，但是 Wheel 创建的初始分页是不变的。

首先需要明确内核的虚拟地址空间结构。64 位 CPU 使用的虚拟地址称作 Canonical Address Form，将完整的 52 位空间分成高低两个部分，更高位是符号扩展。

内核首先建立 0~4GB 的对等映射，也就是内核虚拟地址空间中，0~4GB 映射到 0~4GB 的物理内存。因为许多内存映射设备都处在物理地址 3~4GB 处，而且 52 位的线性地址空间足够使用，并且对等映射非常方便。这部分的映射在切换 64 位方式的时候设置，作为内核的初始分页。

## 请页和映射

要实现动态内存管理，必须要有内存申请和释放的办法。在最下层，内存是按照页为单位进行申请和释放的，内存管理器对新申请的内存页建立映射，将其映射到内核虚拟地址空间中，并建立相关数据结构来管理内存，向其他模块提供 `malloc` 和 `free` 函数的实现。

因此内存分配器底层使用到的 OS 支持是请页和映射。高层提供动态大小区块的申请和释放。

由于内核地址空间中前 4GB 已经映射到物理地址，新申请的物理页只能映射到 4GB 以上的地址。通常，动态扩展的部分称作堆。用户进程的堆是可以动态增长的，但是内核堆是固定的（？）。

## 物理页管理——伙伴算法

伙伴算法也是 Linux 用来物理页的算法，基本思想是相邻的块合并，这样可分配的大小都是 2 的整数次幂。

实现伙伴算法的关键是位图数据结构的支持。Wheel 中，通用的工具函数和数据结构/算法的代码放在 `library` 目录下，实现位图的代码在 `bitmap.{c,h}` 中。

目前实现的物理内存分配是“够用就行”的，但是从论坛上，看到有帖子讨论多线程的情况。一般来说，多线程就是给物理内存分配器加锁，但是这样会影响性能，于是可以使用CPU的`test_and_set`功能。往往检测位图中的0并不是逐个二进制位地检测，而是直接比较`uint64_t`来加速，因此如果要比较特定位，可以用`atomic_and(&block, mask)`来检查。

> 一些汇编指令：bts、cmpxchg、lock前缀

> 英特尔的关于实现多核锁的文档：https://software.intel.com/en-us/articles/implementing-scalable-atomic-locks-for-multi-core-intel-em64t-and-ia32-architectures。

首先使用内联汇编的串搜索指令“rep scasq”，当搜到一个包含未分配页的比特之后，执行“lock bts”和“jc found”

## 虚拟内存管理

目前还没有涉及用户进程，因此虚拟内存管理仅仅供内核使用。即使以后支持用户进程之后，用户进程也会使用自己的内存管理方法，内核只需要向用户进程提供请页和映射功能即可。

简单来说，虚拟内存管理的目的就是写出一个内核使用的 malloc 函数。如果查看一下 GLibC 中的 malloc 实现，会发现非常复杂，GLibC 为了适应多种情况，根据所分配内存大小的不同设计了很多种策略，但是内核需要简单可靠。

此外，考虑程序运行过程中的虚拟地址空间分布，所有的动态内存分配都是发生在堆上的。内核也应该有堆。用户进程的堆就是数据段，并且可以通过系统调用 sbrk 增加堆的大小。然而对于内核来说，堆大小最好固定。

关于内核的堆/栈大小固定，我也曾考虑过动态增长的可能性。参考了 Linux 的实现，发现 Linux 的内核栈是不可以增长的，而且是不可交换（swap）的。内核栈每个进程都要有一个，尚且不允许增长，更何况整个内存只有一份的内核堆。不可交换是很重要的，因为释放内存的时候，如果需要将内存交换到磁盘上，可能影响到释放内存的正常执行，产生死锁。因此，为了安全起见，内核用的数据结构都不能交换。

### SLAB 分配器

GLibC 之所以把 malloc 做得那么复杂，就是为了减少碎片化。大量进行内存申请和释放时，内存的结构就会被这些申请/释放打乱。内核使用 SLAB 分配器来避免这种碎片化，实现高效的内核对象分配。

SLAB 类似“对象池”。

SLAB 的动机就是内核对象的初始化和销毁开销很大，甚至超过为其分配内存的代价。SLAB 会为特定类型或大小的内核对象预分配内存空间，当内核申请这类的对象时，可以直接返回缓存的对象；释放对象的时候，并不真正释放这段内存，而是将该对象的cache标记为可用（free）。

涉及两个术语：
- Cache：一个 Cache 可以存储一个内核对象。分配内存的时候，是以 Cache 为单位进行的。
- Slab：包含若干连续的页，每个 Slab 中存储若干相同大小的 Cache。

slab 可以处于 empty、partial 或者 full 三种状态之一。初始状态下，每个 slab 都是 empty 状态。当内核申请新的内存时，分配器根据申请大小到指定的 slab 中寻找 cache，将这个 slab 标记为 partial。如果某个 slab 已经 full，继续申请这个大小的内存时，分配器就会创建一个新的 slab（这时才会涉及到申请新的物理页）。

（不过这样说来，似乎内核的堆是可以动态增长的，OSDev上的讨论也印证了这一点）

对于比较小的 cache，其 slab 往往就是一个页的大小。

### K&R SLOB

这个是 K&R 提出的内存分配器，非常简单。将内存分割成若干的 chunk，chunk 之间使用双向链表组织起来。申请内存的时候，对这个链表进行一次遍历，找到最优匹配。如果没有找到合适的 chunk，就申请更多的页。

这样做的缺点就是，每次申请内存都要进行一次遍历，优化办法就是使用多个链表，每个链表只存储特定大小范围的 chunk。

### SLAB

这就是之前介绍的对象池技术，里面用到了队列，用来记录每个 cache 的访问热度。

Cache 有类型之分，例如进程描述符、iNode结构体等。kmalloc 是构建在 SLAB 之上的，使用通用类型的 cache。

## Wheel 的实现

根本的需求是实现一个内核使用的 malloc。虽然 malloc 需要自己记录所分配内存的大小，但是实际应用中，往往是分配一个确定的结构体，或者大小确定的数组。因此可以在 free 函数中添加一个 size 字段，malloc_chunk 中不再记录大小。

另一个问题，就是分配粒度。对于大于 4KB 的内存空间，索性使用物理页就可以了，因此 malloc 真正的价值在于分配和管理（远）小于 4KB 大小的内存。

SLAB 根据类型组织 objects，Wheel 不去区分这些类型，仅根据所分配对象的大小进行分类管理。分配的最小尺寸为 16 字节，增量为 8 字节。从 16 字节到 4096 字节，总共 511 个尺寸。如果根据 object 的大小进行分类管理，那么总共需要 511 个 binlist。如果我们需要分配超过 4KB 大小的对象，可以首先分配几个页，然后将剩余部分按照正常的 4K 以下分配方式进行分配。

假设总共 512 个 binlist，每个 binlist 包含一个页，其中有多个 object，此外我们还需要记录里面的每个 object 是否已使用。标记一个 object 是否已分配，适合用位图。因此，还需要仔细编排位图、每个 object 在一个页面中的布局。

## Userland

当系统支持用户层软件之后，就需要考虑用户级程序在内存中的地址空间分布。假设用户程序镜像是一个比ELF简单的格式，系统就可以将其中的代码段、数据段、BSS段直接载入内存，然后在剩余的部分创建堆和栈。如果考虑线程的话，就需要给每个线程建立专门的堆和栈。

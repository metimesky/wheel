## 分页

内存管理的硬件支持是分页机制。在 64 位模式下，分页是强制的，而且是 PAE 分页，PAE 分页意味着支持 2MB 大小的页。

在操作系统启动过程中，切换 64 位模式是最先执行的动作。因此在内存管理模块未启动的时候就需要建立分页。

## 初始分页

初始分页就是在切换64位模式的时候制定的分页映射。虽然当内存管理模块初始化之后可以改变页表，但是 Wheel 创建的初始分页是不变的。

首先需要明确内核的虚拟地址空间结构。64 位 CPU 使用的虚拟地址称作 Canonical Address Form，将完整的 52 位空间分成高低两个部分，更高位是符号扩展。

内核首先建立 0~4GB 的对等映射，也就是内核虚拟地址空间中，0~4GB 映射到 0~4GB 的物理内存。因为许多内存映射设备都处在物理地址 3~4GB 处，而且 52 位的线性地址空间足够使用，并且对等映射非常方便。这部分的映射在切换 64 位方式的时候设置，作为内核的初始分页。

## 请页和映射

要实现动态内存管理，必须要有内存申请和释放的办法。在最下层，内存是按照页为单位进行申请和释放的，内存管理器对新申请的内存页建立映射，将其映射到内核虚拟地址空间中，并建立相关数据结构来管理内存，向其他模块提供 `malloc` 和 `free` 函数的实现。

因此内存分配器底层使用到的 OS 支持是请页和映射。高层提供动态大小区块的申请和释放。

由于内核地址空间中前 4GB 已经映射到物理地址，新申请的物理页只能映射到 4GB 以上的地址。通常，动态扩展的部分称作堆。用户进程的堆是可以动态增长的，但是内核堆是固定的（？）。

## 物理页管理——伙伴算法

伙伴算法也是 Linux 用来物理页的算法，基本思想是相邻的块合并，这样可分配的大小都是 2 的整数次幂。

实现伙伴算法的关键是位图数据结构的支持。Wheel 中，通用的工具函数和数据结构/算法的代码放在 `library` 目录下，实现位图的代码在 `bitmap.{c,h}` 中。

## 虚拟内存管理

目前还没有涉及用户进程，因此虚拟内存管理仅仅供内核使用。即使以后支持用户进程之后，用户进程也会使用自己的内存管理方法，内核只需要向用户进程提供请页和映射功能即可。

简单来说，虚拟内存管理的目的就是写出一个内核使用的 malloc 函数。如果查看一下 GLibC 中的 malloc 实现，会发现非常复杂，GLibC 为了适应多种情况，根据所分配内存大小的不同设计了很多种策略，但是内核需要简单可靠。

此外，考虑程序运行过程中的虚拟地址空间分布，所有的动态内存分配都是发生在堆上的。内核也应该有堆。用户进程的堆就是数据段，并且可以通过系统调用 sbrk 增加堆的大小。然而对于内核来说，堆大小最好固定。

关于内核的堆/栈大小固定，我也曾考虑过动态增长的可能性。参考了 Linux 的实现，发现 Linux 的内核栈是不可以增长的，而且是不可交换（swap）的。内核栈每个进程都要有一个，尚且不允许增长，更何况整个内存只有一份的内核堆。不可交换是很重要的，因为释放内存的时候，如果需要将内存交换到磁盘上，可能影响到释放内存的正常执行，产生死锁。因此，为了安全起见，内核用的数据结构都不能交换。

### SLAB 分配器

GLibC 之所以把 malloc 做得那么复杂，就是为了减少碎片化。大量进行内存申请和释放时，内存的结构就会被这些申请/释放打乱。内核使用 SLAB 分配器来避免这种碎片化，实现高效的内核对象分配。

SLAB 类似“对象池”。

SLAB 的动机就是内核对象的初始化和销毁开销很大，甚至超过为其分配内存的代价。SLAB 会为特定类型或大小的内核对象预分配内存空间，当内核申请这类的对象时，可以直接返回缓存的对象；释放对象的时候，并不真正释放这段内存，而是将该对象的cache标记为可用（free）。

涉及两个术语：
- Cache：一个 Cache 可以存储一个内核对象。分配内存的时候，是以 Cache 为单位进行的。
- Slab：包含若干连续的页，每个 Slab 中存储若干相同大小的 Cache。

slab 可以处于 empty、partial 或者 full 三种状态之一。初始状态下，每个 slab 都是 empty 状态。当内核申请新的内存时，分配器根据申请大小到指定的 slab 中寻找 cache，将这个 slab 标记为 partial。如果某个 slab 已经 full，继续申请这个大小的内存时，分配器就会创建一个新的 slab（这时才会涉及到申请新的物理页）。

（不过这样说来，似乎内核的堆是可以动态增长的，OSDev上的讨论也印证了这一点）

对于比较小的 cache，其 slab 往往就是一个页的大小。

### K&R SLOB

这个是 K&R 提出的内存分配器，非常简单。将内存分割成若干的 chunk，chunk 之间使用双向链表组织起来。申请内存的时候，对这个链表进行一次遍历，找到最优匹配。如果没有找到合适的 chunk，就申请更多的页。

这样做的缺点就是，每次申请内存都要进行一次遍历，优化办法就是使用多个链表，每个链表只存储特定大小范围的 chunk。

### SLAB

这就是之前介绍的对象池技术，里面用到了队列，用来记录每个 cache 的访问热度。

Cache 有类型之分，例如进程描述符、iNode结构体等。kmalloc 是构建在 SLAB 之上的，使用通用类型的 cache。
